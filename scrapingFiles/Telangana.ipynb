{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\OneDrive\\Documents\\redbus_scraping\\redbusWebscraping\\utilities\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project folder, then to 'utilities'\n",
    "project_path = os.path.abspath(\"..\")  # This goes up one level from 'scrapingFiles'\n",
    "utilities_path = os.path.join(project_path, \"utilities\")\n",
    "\n",
    "# Add 'utilities' folder to Python's path if it's not already there\n",
    "if utilities_path not in sys.path:\n",
    "    sys.path.append(utilities_path)\n",
    "print(utilities_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while scraping bus details for https://www.redbus.in/bus-tickets/kodad-to-hyderabad: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00007FF6CF6E38A5+3004357]\n",
      "\t(No symbol) [0x00007FF6CF379970]\n",
      "\t(No symbol) [0x00007FF6CF22582A]\n",
      "\t(No symbol) [0x00007FF6CF275B8E]\n",
      "\t(No symbol) [0x00007FF6CF275E7C]\n",
      "\t(No symbol) [0x00007FF6CF2BEC27]\n",
      "\t(No symbol) [0x00007FF6CF29BC1F]\n",
      "\t(No symbol) [0x00007FF6CF2BBA4C]\n",
      "\t(No symbol) [0x00007FF6CF29B983]\n",
      "\t(No symbol) [0x00007FF6CF267628]\n",
      "\t(No symbol) [0x00007FF6CF268791]\n",
      "\tGetHandleVerifier [0x00007FF6CF70A00D+3161901]\n",
      "\tGetHandleVerifier [0x00007FF6CF75E060+3506048]\n",
      "\tGetHandleVerifier [0x00007FF6CF75400D+3465005]\n",
      "\tGetHandleVerifier [0x00007FF6CF4D0EEB+830987]\n",
      "\t(No symbol) [0x00007FF6CF38467F]\n",
      "\t(No symbol) [0x00007FF6CF3809D4]\n",
      "\t(No symbol) [0x00007FF6CF380B6D]\n",
      "\t(No symbol) [0x00007FF6CF370149]\n",
      "\tBaseThreadInitThunk [0x00007FF8054E7374+20]\n",
      "\tRtlUserThreadStart [0x00007FF8058BCC91+33]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to scrape all pages\n",
    "\n",
    "from commonFunctions import exportCsv, initialize_driver, load_page, scrape_bus_routes\n",
    "from config import redbusUrl\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "URL=redbusUrl\n",
    "\n",
    "# Function to scrape bus details\n",
    "def scrape_bus_details(driver, url, route_name):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Allow the page to load\n",
    "        \n",
    "        # Click the \"View Buses\" button if it exists\n",
    "        try:\n",
    "            view_buses_button = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CLASS_NAME, \"button\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", view_buses_button)\n",
    "            time.sleep(5)  # Wait for buses to load\n",
    "            \n",
    "            # Scroll down to load all bus items\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)  # Wait for the page to load more content\n",
    "            # Find bus item details\n",
    "            bus_name= driver.find_elements(By.CLASS_NAME, \"travels.lh-24.f-bold.d-color\")\n",
    "            bus_type = driver.find_elements(By.CLASS_NAME, \"bus-type.f-12.m-top-16.l-color.evBus\")\n",
    "            departing_time = driver.find_elements(By.CLASS_NAME, \"dp-time.f-19.d-color.f-bold\")\n",
    "            duration = driver.find_elements(By.CLASS_NAME, \"dur.l-color.lh-24\")\n",
    "            reaching_time = driver.find_elements(By.CLASS_NAME, \"bp-time.f-19.d-color.disp-Inline\")\n",
    "            star_rating = driver.find_elements(By.XPATH, \"//div[@class='rating-sec lh-24']\")\n",
    "            price = driver.find_elements(By.CLASS_NAME, \"fare.d-block\")\n",
    "\n",
    "            # Use XPath to handle both seat availability classes\n",
    "            seat_availability = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left m-top-30') or contains(@class, 'seat-left m-top-16')]\")\n",
    "\n",
    "            bus_details = []\n",
    "            for i in range(len(bus_name)): # Total number of bus found on the page\n",
    "                bus_detail = {\n",
    "                    \"Route_Name\": route_name,\n",
    "                    \"Route_Link\": url,\n",
    "                    \"Bus_Name\": bus_name[i].text,\n",
    "                    \"Bus_Type\": bus_type[i].text,\n",
    "                    \"Departing_Time\": departing_time[i].text,\n",
    "                    \"Duration\": duration[i].text,\n",
    "                    \"Reaching_Time\": reaching_time[i].text,\n",
    "                    \"Star_Rating\": star_rating[i].text if i < len(star_rating) else '0',\n",
    "                    \"Price\": price[i].text,\n",
    "                    \"Seat_Availability\": seat_availability[i].text if i < len(seat_availability) else '0'\n",
    "                }\n",
    "                bus_details.append(bus_detail)\n",
    "            return bus_details\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while scraping bus details for {url}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while accessing {url}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def scrape_all_pages():\n",
    "    for page in range(1, 4):  # There are 3 pages\n",
    "        try:\n",
    "            driver = initialize_driver()\n",
    "            load_page(driver,URL)\n",
    "            \n",
    "            if page > 1:\n",
    "                pagination_tab = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, f\"//div[contains(@class, 'DC_117_pageTabs')][text()='{page}']\"))\n",
    "                )\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", pagination_tab)\n",
    "                driver.execute_script(\"arguments[0].click();\", pagination_tab)\n",
    "                time.sleep(5)  # Wait for the page to load\n",
    "            \n",
    "            all_bus_routes_link, all_bus_routes_name = scrape_bus_routes(driver)\n",
    "            # Iterate over each bus route link and scrape the details\n",
    "            for link, name in zip(all_bus_routes_link, all_bus_routes_name):\n",
    "                bus_details = scrape_bus_details(driver, link, name)\n",
    "                if bus_details:\n",
    "                    all_bus_details.extend(bus_details)\n",
    "\n",
    "            driver.quit()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing page {page}: {str(e)}\")\n",
    "\n",
    "# List to hold all bus details\n",
    "all_bus_details = []\n",
    "\n",
    "# Scrape routes and details from all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "exportCsv(all_bus_details,'Telangana_bus_details.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
